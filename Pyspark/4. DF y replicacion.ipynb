{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes y replicación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos un contexto de Spark y otro de SQL\n",
    "\n",
    "Nota: Cargo desde el inicio todos los métodos/modulos que se usarán a lo largo del notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "import pyspark.sql \n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import * \n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType,FloatType\n",
    "from pyspark.sql.types import Row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py4j\n",
      "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
      "\u001b[K     |████████████████████████████████| 198 kB 845 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: py4j\n",
      "Successfully installed py4j-0.10.9.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install py4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/04 13:27:40 WARN Utils: Your hostname, GNULinux resolves to a loopback address: 127.0.1.1; using 192.168.1.69 instead (on interface wlp2s0)\n",
      "21/11/04 13:27:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/11/04 13:27:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "/home/jazzzfm/spark/python/pyspark/sql/context.py:77: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#spark.stop()\n",
    "spark = SparkContext(master=\"local\", appName=\"DF y replicación\")\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para eliminar encabezados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropFirstRow(index,iterator):\n",
    "     return iter(list(iterator)[1:]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación del primer DataFrame\n",
    "\n",
    "Las tres cosas que debes recordar al crear un Dataframe desde un RDDs son:\n",
    "1. En caso de tener encabezado, eliminarlo\n",
    "2. Seleccionar y hacer explícita la seperación de las columnas. Si es necesario castear valores\n",
    "3. Crear el esquema a usarse con los tipos de datos de Spark\n",
    "\n",
    "Cambia el valor de la ruta para que apunte a la ruta donde tienes los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"files/\"\n",
    "\n",
    "deportistaOlimpicoRDD =  spark.textFile(path+\"deportista.csv\").map(lambda line : line.split(\",\"))\n",
    "deportistaOlimpico2RDD = spark.textFile(path+\"deportista2.csv\").map(lambda line : line.split(\",\"))\n",
    "deportistaOlimpicoRDD = deportistaOlimpicoRDD.union(deportistaOlimpico2RDD)\n",
    "\n",
    "deportistaOlimpicoRDD=deportistaOlimpicoRDD.mapPartitionsWithIndex(dropFirstRow)\n",
    "\n",
    "deportistaOlimpicoRDD = deportistaOlimpicoRDD.map(lambda l : (\n",
    "int(l[0]),\n",
    "l[1],\n",
    "int(l[2]),\n",
    "int(l[3]),\n",
    "int(l[4]),\n",
    "float(l[5]),\n",
    "int(l[6])\n",
    "))\n",
    "\n",
    "schema = StructType([\n",
    "StructField(\"deportista_id\",IntegerType(),False)     ,\n",
    "StructField(\"nombre\",StringType(),False)        ,\n",
    "StructField(\"genero\",IntegerType(),False)        ,\n",
    "StructField(\"edad\",IntegerType(),True)      ,\n",
    "StructField(\"altura\",IntegerType(),True)        ,\n",
    "StructField(\"peso\",FloatType(),True)      ,\n",
    "StructField(\"equipo_id\",IntegerType(),True)     \n",
    "])\n",
    "\n",
    "deportistaOlimpicoDF = sqlContext.createDataFrame(deportistaOlimpicoRDD,schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de DF desde archivo\n",
    "\n",
    "En el caso de la creación de un DF desde cero, solo debemos de indicar la estructura, nombre del archivo y opcionalmente si posee o no encabezado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "deportesOlimpicosRDDSchema = StructType(\n",
    "    [StructField(\"deporte_id\",IntegerType(),False),\n",
    "     StructField(\"deporte\",StringType(),False)\n",
    "    ])\n",
    "\n",
    "deportesDF = sqlContext.read.schema(deportesOlimpicosRDDSchema).option(\"header\",\"true\").csv(path+\"deporte.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDF\n",
    "\n",
    "Nota: Este apartado en el curso se pone al final.\n",
    "\n",
    "Para ejemplificar la función creada por el usuario, cargamos deportistaError el cual tiene ausencia de valores.\n",
    "\n",
    "Con la UDF solucionamos el error. Esta no es una solución definitiva, solo es demostrativa para explicar como crear una UDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "deportistaOlimpicoRDD =  spark.textFile(path+\"deportistaError.csv\").map(lambda line : line.split(\",\"))\n",
    "deportistaOlimpicoRDD=deportistaOlimpicoRDD.mapPartitionsWithIndex(dropFirstRow)\n",
    "\n",
    "deportistaOlimpicoRDD = deportistaOlimpicoRDD.map(lambda l : (\n",
    "l[0],\n",
    "l[1],\n",
    "l[2],\n",
    "l[3],\n",
    "l[4],\n",
    "l[5],\n",
    "l[6]\n",
    "))\n",
    "\n",
    "schema = StructType([\n",
    "StructField(\"deportista_id\",StringType(),False)     ,\n",
    "StructField(\"nombre\",StringType(),False)        ,\n",
    "StructField(\"genero\",StringType(),False)        ,\n",
    "StructField(\"edad\",StringType(),True)      ,\n",
    "StructField(\"altura\",StringType(),True)        ,\n",
    "StructField(\"peso\",StringType(),True)      ,\n",
    "StructField(\"equipo_id\",StringType(),True)     \n",
    "])\n",
    "\n",
    "deportistaError = sqlContext.createDataFrame(deportistaOlimpicoRDD,schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|deportista_id|              nombre|genero|edad|altura|peso|equipo_id|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|            1|           A Dijiang|     1|  24|   180|  80|      199|\n",
      "|            2|            A Lamusi|     1|  23|   170|  60|      199|\n",
      "|            3| Gunnar Nielsen Aaby|     1|  24|      |    |      273|\n",
      "|            4|Edgar Lindenau Aabye|     1|  34|      |    |      278|\n",
      "|            5|Christine Jacoba ...|     2|  21|   185|  82|      705|\n",
      "|            6|     Per Knut Aaland|     1|  31|   188|  75|     1096|\n",
      "|            7|        John Aalberg|     1|  31|   183|  72|     1096|\n",
      "|            8|\"Cornelia \"\"Cor\"\"...|     2|  18|   168|    |      705|\n",
      "|            9|    Antti Sami Aalto|     1|  26|   186|  96|      350|\n",
      "|           10|\"Einar Ferdinand ...|     1|  26|      |    |      350|\n",
      "|           11|  Jorma Ilmari Aalto|     1|  22|   182|76.5|      350|\n",
      "|           12|   Jyri Tapani Aalto|     1|  31|   172|  70|      350|\n",
      "|           13|  Minna Maarit Aalto|     2|  30|   159|55.5|      350|\n",
      "|           14|Pirjo Hannele Aal...|     2|  32|   171|  65|      350|\n",
      "|           15|Arvo Ossian Aaltonen|     1|  22|      |    |      350|\n",
      "|           16|Juhamatti Tapio A...|     1|  28|   184|  85|      350|\n",
      "|           17|Paavo Johannes Aa...|     1|  28|   175|  64|      350|\n",
      "|           18|Timo Antero Aaltonen|     1|  31|   189| 130|      350|\n",
      "|           19|Win Valdemar Aalt...|     1|  54|      |    |      350|\n",
      "|           20|  Kjetil Andr Aamodt|     1|  20|   176|  85|      742|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "deportistaError.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.69:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DF y replicación</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=DF y replicación>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de UDF\n",
    "\n",
    "Los pasos para crear la udf son:\n",
    "\n",
    "1. Crear la función base\n",
    "2. Registrarla como udf\n",
    "3. Indicar al sqlContext que la usaremos como función nativa en sqlContext (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|altura|\n",
      "+------+\n",
      "|   180|\n",
      "|   170|\n",
      "|  null|\n",
      "|  null|\n",
      "|   185|\n",
      "|   188|\n",
      "|   183|\n",
      "|   168|\n",
      "|   186|\n",
      "|  null|\n",
      "|   182|\n",
      "|   172|\n",
      "|   159|\n",
      "|   171|\n",
      "|  null|\n",
      "|   184|\n",
      "|   175|\n",
      "|   189|\n",
      "|  null|\n",
      "|   176|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def ci(value: str) -> int:\n",
    "    return int(value) if len(value) > 0 else None\n",
    "\n",
    "ci_udf = udf(lambda z : ci(z), IntegerType())\n",
    "\n",
    "sqlContext.udf.register(\"ci_udf\", ci_udf)\n",
    "\n",
    "deportistaError.select(ci_udf(\"altura\").alias(\"altura\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|deportista_id|              nombre|genero|edad|altura|peso|equipo_id|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|            1|           A Dijiang|     1|  24|   180|  80|      199|\n",
      "|            2|            A Lamusi|     1|  23|   170|  60|      199|\n",
      "|            3| Gunnar Nielsen Aaby|     1|  24|      |    |      273|\n",
      "|            4|Edgar Lindenau Aabye|     1|  34|      |    |      278|\n",
      "|            5|Christine Jacoba ...|     2|  21|   185|  82|      705|\n",
      "|            6|     Per Knut Aaland|     1|  31|   188|  75|     1096|\n",
      "|            7|        John Aalberg|     1|  31|   183|  72|     1096|\n",
      "|            8|\"Cornelia \"\"Cor\"\"...|     2|  18|   168|    |      705|\n",
      "|            9|    Antti Sami Aalto|     1|  26|   186|  96|      350|\n",
      "|           10|\"Einar Ferdinand ...|     1|  26|      |    |      350|\n",
      "|           11|  Jorma Ilmari Aalto|     1|  22|   182|76.5|      350|\n",
      "|           12|   Jyri Tapani Aalto|     1|  31|   172|  70|      350|\n",
      "|           13|  Minna Maarit Aalto|     2|  30|   159|55.5|      350|\n",
      "|           14|Pirjo Hannele Aal...|     2|  32|   171|  65|      350|\n",
      "|           15|Arvo Ossian Aaltonen|     1|  22|      |    |      350|\n",
      "|           16|Juhamatti Tapio A...|     1|  28|   184|  85|      350|\n",
      "|           17|Paavo Johannes Aa...|     1|  28|   175|  64|      350|\n",
      "|           18|Timo Antero Aaltonen|     1|  31|   189| 130|      350|\n",
      "|           19|Win Valdemar Aalt...|     1|  54|      |    |      350|\n",
      "|           20|  Kjetil Andr Aamodt|     1|  20|   176|  85|      742|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deportistaError.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reto\n",
    "\n",
    "Dar vida a todos los archivos como Dataframes.\n",
    "\n",
    "Se anexa una solución probable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "paisesRDD = spark.textFile(path+\"paises.csv\").map(lambda line : line.split(\",\"))\n",
    "paisesRDD = paisesRDD.mapPartitionsWithIndex(dropFirstRow)\n",
    "\n",
    "paisesRDD = paisesRDD.map(lambda l : (\n",
    "int(l[0]),\n",
    "l[1],\n",
    "l[2]\n",
    "))\n",
    "\n",
    "schema = StructType([\n",
    "StructField(\"id\",IntegerType(),False),\n",
    "StructField(\"equipo\",StringType(),False),\n",
    "StructField(\"sigla\",StringType(),False)\n",
    "])\n",
    "\n",
    "paisesDF = sqlContext.createDataFrame(paisesRDD,schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evento_id,evento,deporte_id\r\n",
      "1,Basketball Men's Basketball,1\r\n",
      "2,Judo Men's Extra-Lightweight,2\r\n",
      "3,Football Men's Football,3\r\n",
      "4,Tug-Of-War Men's Tug-Of-War,4\r\n",
      "5,Speed Skating Women's 500 metres,5\r\n",
      "6,\"Speed Skating Women's 1,000 metres\",5\r\n",
      "7,Cross Country Skiing Men's 10 kilometres,6\r\n",
      "8,Cross Country Skiing Men's 50 kilometres,6\r\n",
      "9,Cross Country Skiing Men's 10/15 kilometres Pursuit,6\r\n"
     ]
    }
   ],
   "source": [
    "!head files/evento.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventoSchema= StructType([\n",
    "    StructField(\"evento_id\",IntegerType(),False),\n",
    "    StructField(\"evento\",StringType(),False),\n",
    "    StructField(\"deporte_id\",IntegerType(),False)\n",
    "])\n",
    "\n",
    "deportesOlimpicosDF = sqlContext.read.schema(eventoSchema).option(\"header\",\"true\").csv(path+\"evento.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "juegoSchema = StructType([\n",
    "    StructField(\"juego_id\",IntegerType(),False),\n",
    "    StructField(\"anio\",StringType(),False),\n",
    "    StructField(\"temporada\",StringType(),False),\n",
    "    StructField(\"ciudad\",StringType(),False),\n",
    "])\n",
    "juegoDF = sqlContext.read.schema(juegoSchema).option(\"header\",\"true\").csv(path+\"juegos.csv\")\n",
    "\n",
    "resultadoSchema = StructType([\n",
    "    StructField(\"resultado_id\",IntegerType(),False),\n",
    "    StructField(\"medalla\",StringType(),False),\n",
    "    StructField(\"deportista_id\",IntegerType(),False),\n",
    "    StructField(\"juego_id\",IntegerType(),False),\n",
    "    StructField(\"evento_id\",IntegerType(),False),\n",
    "])\n",
    "resultadoDF = sqlContext.read.schema(resultadoSchema).option(\"header\",\"true\").csv(path+\"resultados.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(deporte_id=1, deporte='Basketball'),\n",
       " Row(deporte_id=2, deporte='Judo'),\n",
       " Row(deporte_id=3, deporte='Football'),\n",
       " Row(deporte_id=4, deporte='Tug-Of-War'),\n",
       " Row(deporte_id=5, deporte='Speed Skating')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deportesDF.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(evento_id=1, evento=\"Basketball Men's Basketball\", deporte_id=1),\n",
       " Row(evento_id=2, evento=\"Judo Men's Extra-Lightweight\", deporte_id=2),\n",
       " Row(evento_id=3, evento=\"Football Men's Football\", deporte_id=3),\n",
       " Row(evento_id=4, evento=\"Tug-Of-War Men's Tug-Of-War\", deporte_id=4),\n",
       " Row(evento_id=5, evento=\"Speed Skating Women's 500 metres\", deporte_id=5)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deportesOlimpicosDF.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+\n",
      "| id|              equipo|sigla|\n",
      "+---+--------------------+-----+\n",
      "|  1|         30. Februar|  AUT|\n",
      "|  2|A North American ...|  MEX|\n",
      "|  3|           Acipactli|  MEX|\n",
      "|  4|             Acturus|  ARG|\n",
      "|  5|         Afghanistan|  AFG|\n",
      "|  6|            Akatonbo|  IRL|\n",
      "|  7|            Alain IV|  SUI|\n",
      "|  8|             Albania|  ALB|\n",
      "|  9|              Alcaid|  POR|\n",
      "| 10|            Alcyon-6|  FRA|\n",
      "| 11|            Alcyon-7|  FRA|\n",
      "| 12|           Aldebaran|  ITA|\n",
      "| 13|        Aldebaran II|  ITA|\n",
      "| 14|              Aletta|  IRL|\n",
      "| 15|             Algeria|  ALG|\n",
      "| 16|         Ali-Baba II|  SWE|\n",
      "| 17|         Ali-Baba IV|  SUI|\n",
      "| 18|         Ali-Baba IX|  SUI|\n",
      "| 19|         Ali-Baba VI|  SUI|\n",
      "| 20|             Allegro|  FRA|\n",
      "+---+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paisesDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/04 14:42:24 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 5, schema size: 4\n",
      "CSV file: file:///home/jazzzfm/PersonalProjects/JazzzDevelopmentWithSpark/curso-apache-spark-platzi/files/juegos.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(juego_id=1, anio='1896 Verano', temporada='1896', ciudad='Verano'),\n",
       " Row(juego_id=2, anio='1900 Verano', temporada='1900', ciudad='Verano'),\n",
       " Row(juego_id=3, anio='1904 Verano', temporada='1904', ciudad='Verano'),\n",
       " Row(juego_id=4, anio='1906 Verano', temporada='1906', ciudad='Verano'),\n",
       " Row(juego_id=5, anio='1908 Verano', temporada='1908', ciudad='Verano')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "juegoDF.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(deportista_id=1, nombre='A Dijiang', genero=1, edad=24, altura=180, peso=80.0, equipo_id=199),\n",
       " Row(deportista_id=2, nombre='A Lamusi', genero=1, edad=23, altura=170, peso=60.0, equipo_id=199),\n",
       " Row(deportista_id=3, nombre='Gunnar Nielsen Aaby', genero=1, edad=24, altura=0, peso=0.0, equipo_id=273),\n",
       " Row(deportista_id=4, nombre='Edgar Lindenau Aabye', genero=1, edad=34, altura=0, peso=0.0, equipo_id=278),\n",
       " Row(deportista_id=5, nombre='Christine Jacoba Aaftink', genero=2, edad=21, altura=185, peso=82.0, equipo_id=705)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deportistaOlimpicoDF.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(resultado_id=1, medalla='NA', deportista_id=1, juego_id=39, evento_id=1),\n",
       " Row(resultado_id=2, medalla='NA', deportista_id=2, juego_id=49, evento_id=2),\n",
       " Row(resultado_id=3, medalla='NA', deportista_id=3, juego_id=7, evento_id=3),\n",
       " Row(resultado_id=4, medalla='Gold', deportista_id=4, juego_id=2, evento_id=4),\n",
       " Row(resultado_id=5, medalla='NA', deportista_id=5, juego_id=36, evento_id=5)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultadoDF.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisión de esquema\n",
    "\n",
    "En ocasiones nosotros no creamos los Dataframes y la estrucutra es desconocida para nosotros. con ayuda del método 'printSchema' podemos conocer el esquema del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- deporte_id: integer (nullable = true)\n",
      " |-- deporte: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deportesDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- deportista_id: integer (nullable = false)\n",
      " |-- nombre: string (nullable = false)\n",
      " |-- genero: integer (nullable = false)\n",
      " |-- edad: integer (nullable = true)\n",
      " |-- altura: integer (nullable = true)\n",
      " |-- peso: float (nullable = true)\n",
      " |-- equipo_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deportistaOlimpicoDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operaciones de renombrado y eliminación\n",
    "\n",
    "Para renombrar una columna de un DF, podemos usar el método 'withColumnRenamed' o 'alias'.\n",
    "\n",
    "Para eliminar columnas, podemos usar el método 'drop' o simplemente selecionar las columnas que deseamos y sobreesciribr el DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "deportistaOlimpicoDF = deportistaOlimpicoDF\\\n",
    "                        .withColumnRenamed(\"genero\",\"sexo\")\\\n",
    "                        .drop(\"altura\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- deportista_id: integer (nullable = false)\n",
      " |-- nombre: string (nullable = false)\n",
      " |-- sexo: integer (nullable = false)\n",
      " |-- edad: integer (nullable = true)\n",
      " |-- peso: float (nullable = true)\n",
      " |-- equipo_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deportistaOlimpicoDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "deportistaOlimpicoDF = deportistaOlimpicoDF\\\n",
    "            .select(\"deportista_id\",\"nombre\", col(\"edad\").alias(\"edadAlJugar\"),\"equipo_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+-----------+---------+\n",
      "|deportista_id|              nombre|edadAlJugar|equipo_id|\n",
      "+-------------+--------------------+-----------+---------+\n",
      "|            1|           A Dijiang|         24|      199|\n",
      "|            2|            A Lamusi|         23|      199|\n",
      "|            3| Gunnar Nielsen Aaby|         24|      273|\n",
      "|            4|Edgar Lindenau Aabye|         34|      278|\n",
      "|            5|Christine Jacoba ...|         21|      705|\n",
      "+-------------+--------------------+-----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deportistaOlimpicoDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado de valores\n",
    "\n",
    "Como con el uso de RDDs, podemos usar el método 'filter' para selecionar subconjuntos.\n",
    "\n",
    "filter permite usar operaciones lógicas y de comparación como <,>,>=,!= , &,| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "deportistaOlimpicoDF = deportistaOlimpicoDF.filter( (deportistaOlimpicoDF.edadAlJugar != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 18:>                                                         (0 + 1) / 2]\r",
      "\r",
      "[Stage 18:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+-----------+---------+\n",
      "|deportista_id|              nombre|edadAlJugar|equipo_id|\n",
      "+-------------+--------------------+-----------+---------+\n",
      "|        71691|  Dimitrios Loundras|         10|      333|\n",
      "|        70616|          Liu Luyang|         11|      199|\n",
      "|       118925|Megan Olwen Deven...|         11|      413|\n",
      "|        52070|        Etsuko Inada|         11|      514|\n",
      "|        22411|Magdalena Cecilia...|         11|      413|\n",
      "|        40129|    Luigina Giavotti|         11|      507|\n",
      "|        47618|Sonja Henie Toppi...|         11|      742|\n",
      "|        76675|   Marcelle Matthews|         11|      967|\n",
      "|        37333|Carlos Bienvenido...|         11|      982|\n",
      "|        51268|      Beatrice Hutiu|         11|      861|\n",
      "|       126307|        Liana Vicens|         11|      825|\n",
      "|        48939|             Ho Gang|         12|      738|\n",
      "|        49142|        Jan Hoffmann|         12|      302|\n",
      "|        42835|   Werner Grieshofer|         12|       71|\n",
      "|        54620|Belita Gladys Lyn...|         12|      413|\n",
      "|        31203|Patricia Anne Pat...|         12|      967|\n",
      "|        43528|Antoinette Joyce ...|         12|      172|\n",
      "|        46578|        Diana Hatler|         12|      825|\n",
      "|        59727|Marika Kilius Zah...|         12|      399|\n",
      "|        40296|    Alain C. Giletti|         12|      362|\n",
      "+-------------+--------------------+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "deportistaOlimpicoDF.sort(\"edadAlJugar\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+-----------+---------+\n",
      "|deportista_id|              nombre|edadAlJugar|equipo_id|\n",
      "+-------------+--------------------+-----------+---------+\n",
      "|            1|           A Dijiang|         24|      199|\n",
      "|            2|            A Lamusi|         23|      199|\n",
      "|            3| Gunnar Nielsen Aaby|         24|      273|\n",
      "|            4|Edgar Lindenau Aabye|         34|      278|\n",
      "|            5|Christine Jacoba ...|         21|      705|\n",
      "|            6|     Per Knut Aaland|         31|     1096|\n",
      "|            7|        John Aalberg|         31|     1096|\n",
      "|            8|Cornelia Cor Aalt...|         18|      705|\n",
      "|            9|    Antti Sami Aalto|         26|      350|\n",
      "|           10|Einar Ferdinand E...|         26|      350|\n",
      "|           11|  Jorma Ilmari Aalto|         22|      350|\n",
      "|           12|   Jyri Tapani Aalto|         31|      350|\n",
      "|           13|  Minna Maarit Aalto|         30|      350|\n",
      "|           14|Pirjo Hannele Aal...|         32|      350|\n",
      "|           15|Arvo Ossian Aaltonen|         22|      350|\n",
      "|           16|Juhamatti Tapio A...|         28|      350|\n",
      "|           17|Paavo Johannes Aa...|         28|      350|\n",
      "|           18|Timo Antero Aaltonen|         31|      350|\n",
      "|           19|Win Valdemar Aalt...|         54|      350|\n",
      "|           20|  Kjetil Andr Aamodt|         20|      742|\n",
      "+-------------+--------------------+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deportistaOlimpicoDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unión de DF\n",
    "\n",
    "Las operaciones conocidas como Join en SQL, tienen una impementación similar, ya que  el método 'join' recibe tres componentes:\n",
    "\n",
    "| Orden | Argumento | Descripción |\n",
    "|-------|--------|-----|\n",
    "|1|dataFrame|dataFrame con el que queremos realizar el cruce|\n",
    "|2|Cruze|Operación lógica a realizar para poder unir los Dataframes|\n",
    "|3|Tipo|El tipo de join a realizar: \"Left\", \"Right\",etc|\n",
    "\n",
    "No olvides que un join es una operación binaria. Por lo que si deseas unir mas DF, deberás realizar multiples joins\n",
    "\n",
    "Posterior a los joins realizados, debemos de realizar una operación select para indicar que valores queremos. \n",
    "\n",
    "En el caso de campos repetidos, podemos hacer explícito el dataframe de origen y para evitar confusón, utilizar alias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/04 15:42:04 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , nombre_juego\n",
      " Schema: juego_id, anio\n",
      "Expected: juego_id but found: \n",
      "CSV file: file:///home/jazzzfm/PersonalProjects/JazzzDevelopmentWithSpark/curso-apache-spark-platzi/files/juegos.csv\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-------+-------------+--------------------+\n",
      "|              nombre|Edad al jugar|medalla| Año de juego|Nombre de disciplina|\n",
      "+--------------------+-------------+-------+-------------+--------------------+\n",
      "|           A Dijiang|           24|     NA|  1992 Verano|Basketball Men's ...|\n",
      "|            A Lamusi|           23|     NA|  2012 Verano|Judo Men's Extra-...|\n",
      "| Gunnar Nielsen Aaby|           24|     NA|  1920 Verano|Football Men's Fo...|\n",
      "|Edgar Lindenau Aabye|           34|   Gold|  1900 Verano|Tug-Of-War Men's ...|\n",
      "|Christine Jacoba ...|           21|     NA|1994 Invierno|Speed Skating Wom...|\n",
      "|Christine Jacoba ...|           21|     NA|1994 Invierno|Speed Skating Wom...|\n",
      "|Christine Jacoba ...|           21|     NA|1992 Invierno|Speed Skating Wom...|\n",
      "|Christine Jacoba ...|           21|     NA|1992 Invierno|Speed Skating Wom...|\n",
      "|Christine Jacoba ...|           21|     NA|1988 Invierno|Speed Skating Wom...|\n",
      "|Christine Jacoba ...|           21|     NA|1988 Invierno|Speed Skating Wom...|\n",
      "|     Per Knut Aaland|           31|     NA|1994 Invierno|Cross Country Ski...|\n",
      "|     Per Knut Aaland|           31|     NA|1994 Invierno|Cross Country Ski...|\n",
      "|     Per Knut Aaland|           31|     NA|1994 Invierno|Cross Country Ski...|\n",
      "|     Per Knut Aaland|           31|     NA|1994 Invierno|Cross Country Ski...|\n",
      "|     Per Knut Aaland|           31|     NA|1992 Invierno|Cross Country Ski...|\n",
      "|     Per Knut Aaland|           31|     NA|1992 Invierno|Cross Country Ski...|\n",
      "|     Per Knut Aaland|           31|     NA|1992 Invierno|Cross Country Ski...|\n",
      "|     Per Knut Aaland|           31|     NA|1992 Invierno|Cross Country Ski...|\n",
      "|        John Aalberg|           31|     NA|1994 Invierno|Cross Country Ski...|\n",
      "|        John Aalberg|           31|     NA|1994 Invierno|Cross Country Ski...|\n",
      "+--------------------+-------------+-------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deportistaOlimpicoDF.join(\n",
    "    resultadoDF,\n",
    "    deportistaOlimpicoDF.deportista_id == resultadoDF.deportista_id,\n",
    "    \"left\") \\\n",
    "    .join(\n",
    "    juegoDF,\n",
    "    juegoDF.juego_id == resultadoDF.juego_id,\n",
    "    \"left\") \\\n",
    "    .join(\n",
    "    deportesOlimpicosDF,\n",
    "    deportesOlimpicosDF.evento_id == resultadoDF.evento_id,\n",
    "    \"left\") \\\n",
    "    .select(\n",
    "        deportistaOlimpicoDF.nombre,\n",
    "        col(\"edadAlJugar\").alias(\"Edad al jugar\"),\n",
    "        \"medalla\",\n",
    "        col(\"anio\").alias(\"Año de juego\"),\n",
    "        deportesOlimpicosDF.evento.alias(\"Nombre de disciplina\")\n",
    "    )\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma forma que una instrucción SQL posee una jerarquía para poder funcionar y retornar correctamente los valores que deseamos. Los DF estan reguidos por las mismas reglas, es decir la misma jerarquía"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones escalares\n",
    "\n",
    "De la misma forma que SQL posee funciones para poder obtener estadísticas. DF hereda el mismo concepto apoyandose de los métodos 'groupBy', \"agg\" y los ya conocidos de sql \"count\",\"sum\",\"avg\" etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+----------+\n",
      "|evento_id|              evento|deporte_id|\n",
      "+---------+--------------------+----------+\n",
      "|        1|Basketball Men's ...|         1|\n",
      "|        2|Judo Men's Extra-...|         2|\n",
      "|        3|Football Men's Fo...|         3|\n",
      "|        4|Tug-Of-War Men's ...|         4|\n",
      "|        5|Speed Skating Wom...|         5|\n",
      "|        6|Speed Skating Wom...|         5|\n",
      "|        7|Cross Country Ski...|         6|\n",
      "|        8|Cross Country Ski...|         6|\n",
      "|        9|Cross Country Ski...|         6|\n",
      "|       10|Cross Country Ski...|         6|\n",
      "|       11|Cross Country Ski...|         6|\n",
      "|       12|Athletics Women's...|         7|\n",
      "|       13|Athletics Women's...|         7|\n",
      "|       14|Ice Hockey Men's ...|         8|\n",
      "|       15|Swimming Men's 40...|         9|\n",
      "|       16|Badminton Men's S...|        10|\n",
      "|       17|Sailing Women's W...|        11|\n",
      "|       18|Biathlon Women's ...|        12|\n",
      "|       19|Swimming Men's 20...|         9|\n",
      "|       20|Swimming Men's 40...|         9|\n",
      "+---------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deportesOlimpicosDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el ejercicio, buscaremos conocer cuantas medallas ha ganado un pais en cada juego olimpico.\n",
    "\n",
    "Primero realizamos la batería de joins que nos permitan identificar todos los valores que necesitamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "medallistaXAnio = deportistaOlimpicoDF\\\n",
    "        .join(\n",
    "            resultadoDF, \n",
    "            deportistaOlimpicoDF.deportista_id ==resultadoDF.deportista_id,\n",
    "            \"left\"\n",
    "            )\\\n",
    "        .join(\n",
    "            juegoDF, \n",
    "            juegoDF.juego_id == resultadoDF.juego_id,\n",
    "            \"left\"\n",
    "            )\\\n",
    "        .join(\n",
    "            paisesDF,\n",
    "            deportistaOlimpicoDF.equipo_id == paisesDF.id,\n",
    "            \"left\"\n",
    "            ) \\\n",
    "        .join(\n",
    "            deportesOlimpicosDF,\n",
    "            deportesOlimpicosDF.evento_id == resultadoDF.evento_id,\n",
    "            \"left\"\n",
    "            ) \\\n",
    "        .join(\n",
    "            deportesDF,\n",
    "            deportesOlimpicosDF.deporte_id == deportesDF.deporte_id,\n",
    "            \"left\"\n",
    "            ) \\\n",
    "        .select(\"sigla\",\n",
    "                \"anio\",\n",
    "                \"medalla\",\n",
    "                deportesOlimpicosDF.evento.alias(\"Nombre subdisciplina\"),\n",
    "                deportesDF.deporte.alias(\"Nombre disciplina\"),\n",
    "                deportistaOlimpicoDF.nombre,   \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/04 16:01:02 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , nombre_juego\n",
      " Schema: juego_id, anio\n",
      "Expected: juego_id but found: \n",
      "CSV file: file:///home/jazzzfm/PersonalProjects/JazzzDevelopmentWithSpark/curso-apache-spark-platzi/files/juegos.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-------+--------------------+--------------------+--------------------+\n",
      "|sigla|         anio|medalla|Nombre subdisciplina|   Nombre disciplina|              nombre|\n",
      "+-----+-------------+-------+--------------------+--------------------+--------------------+\n",
      "|  CHN|  1992 Verano|     NA|Basketball Men's ...|          Basketball|           A Dijiang|\n",
      "|  CHN|  2012 Verano|     NA|Judo Men's Extra-...|                Judo|            A Lamusi|\n",
      "|  DEN|  1920 Verano|     NA|Football Men's Fo...|            Football| Gunnar Nielsen Aaby|\n",
      "|  SWE|  1900 Verano|   Gold|Tug-Of-War Men's ...|          Tug-Of-War|Edgar Lindenau Aabye|\n",
      "|  NED|1994 Invierno|     NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|  NED|1994 Invierno|     NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|  NED|1992 Invierno|     NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|  NED|1992 Invierno|     NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|  NED|1988 Invierno|     NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|  NED|1988 Invierno|     NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|  USA|1994 Invierno|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA|1994 Invierno|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA|1994 Invierno|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA|1994 Invierno|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA|1992 Invierno|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA|1992 Invierno|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA|1992 Invierno|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA|1992 Invierno|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA|1994 Invierno|     NA|Cross Country Ski...|Cross Country Skiing|        John Aalberg|\n",
      "|  USA|1994 Invierno|     NA|Cross Country Ski...|Cross Country Skiing|        John Aalberg|\n",
      "+-----+-------------+-------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "medallistaXAnio.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previo, identificamos el uso del método \"like\".\n",
    "\n",
    "El cual es util cuando no sabemos el nombre completo o correcto de una columna deseada. \n",
    "\n",
    "En este ejemplo, apartir de todos los juegos de Ski Aplino Femenino, obtenemos la competencias en las que participó el pais. Recuerda que la columna medalla aun posee valores NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/04 16:12:27 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , nombre_juego\n",
      " Schema: juego_id, anio\n",
      "Expected: juego_id but found: \n",
      "CSV file: file:///home/jazzzfm/PersonalProjects/JazzzDevelopmentWithSpark/curso-apache-spark-platzi/files/juegos.csv\n",
      "[Stage 147:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-----+\n",
      "|Sigla|         anio|count|\n",
      "+-----+-------------+-----+\n",
      "|  SUI|2014 Invierno|   19|\n",
      "|  URS|1984 Invierno|    2|\n",
      "|  ROU|2014 Invierno|    8|\n",
      "|  LIE|1998 Invierno|    7|\n",
      "|  USA|1952 Invierno|   12|\n",
      "|  CYP|1992 Invierno|    2|\n",
      "|  POR|2014 Invierno|    2|\n",
      "|  BRA|2002 Invierno|    1|\n",
      "|  FRA|2010 Invierno|   17|\n",
      "|  CZE|2002 Invierno|   12|\n",
      "|  TCH|1984 Invierno|   10|\n",
      "|  ROU|1988 Invierno|    5|\n",
      "|  SVK|2006 Invierno|   16|\n",
      "|  ISL|1992 Invierno|    2|\n",
      "|  LIE|1988 Invierno|    9|\n",
      "|  SUI|1992 Invierno|   19|\n",
      "|  NOR|1960 Invierno|   11|\n",
      "|  AND|2014 Invierno|    3|\n",
      "|  ESP|2010 Invierno|    7|\n",
      "|  ITA|2014 Invierno|   18|\n",
      "+-----+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "medallistaXAnio.where(\n",
    "    col(\"Nombre subdisciplina\").like(\"Alpine Skiing Wo%\")) \\\n",
    "    .sort(\"anio\") \\\n",
    "    .groupBy(\"Sigla\",\"anio\")\\\n",
    "    .count() \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este paso nos quedamos solo con medallas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "medallistaXAnio2 = medallistaXAnio\\\n",
    "    .filter(medallistaXAnio.medalla != \"NA\")\\\n",
    "    .sort(\"anio\")\\\n",
    "    .groupBy(\"Sigla\",\"anio\",\"Nombre subdisciplina\")\\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forma recomendada para agrupar\n",
    "\n",
    "El método 'agg' es la forma recomendada para hacer agrupaciones ya que brinda la oportunidad de escalar la cantidad de operaciones escalares a realizar en un mismo DF.\n",
    "\n",
    "Es claro que si solo realizamos una operación de agrupación, el uso de 'agg' es excesivo, esta es la recomendación oficial de uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/04 16:29:42 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , nombre_juego\n",
      " Schema: juego_id, anio\n",
      "Expected: juego_id but found: \n",
      "CSV file: file:///home/jazzzfm/PersonalProjects/JazzzDevelopmentWithSpark/curso-apache-spark-platzi/files/juegos.csv\n",
      "[Stage 190:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-----------------+------------------+\n",
      "|Sigla|       anio|Total de medallas| Medallas promedio|\n",
      "+-----+-----------+-----------------+------------------+\n",
      "|  URS|1980 Verano|              442|2.8333333333333335|\n",
      "|  USA|1904 Verano|              356|               4.0|\n",
      "|  USA|1984 Verano|              352| 2.550724637681159|\n",
      "|  USA|2008 Verano|              318|3.4565217391304346|\n",
      "|  GBR|1908 Verano|              305| 4.066666666666666|\n",
      "|  URS|1988 Verano|              300|2.6548672566371683|\n",
      "|  URS|1976 Verano|              286| 2.623853211009174|\n",
      "|  GDR|1980 Verano|              264|2.5142857142857142|\n",
      "|  USA|2016 Verano|              263| 2.481132075471698|\n",
      "|  USA|2004 Verano|              262| 2.977272727272727|\n",
      "|  USA|1996 Verano|              259|2.9101123595505616|\n",
      "|  USA|2012 Verano|              248|2.7252747252747254|\n",
      "|  USA|2000 Verano|              242|             3.025|\n",
      "|  GER|1936 Verano|              224| 2.574712643678161|\n",
      "|  USA|1992 Verano|              224|2.3092783505154637|\n",
      "|  URS|1972 Verano|              214|2.3777777777777778|\n",
      "|  USA|1988 Verano|              207|2.5555555555555554|\n",
      "|  GDR|1976 Verano|              193| 2.608108108108108|\n",
      "|  USA|1920 Verano|              193|2.9692307692307693|\n",
      "|  URS|1968 Verano|              192| 2.341463414634146|\n",
      "+-----+-----------+-----------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "medallistaXAnio2\\\n",
    "    .groupBy(\"Sigla\",\"anio\") \\\n",
    "    .agg(\n",
    "        sum(\"count\").alias(\"Total de medallas\"),\\\n",
    "        avg(\"count\").alias(\"Medallas promedio\")\n",
    "        )\\\n",
    "    .sort(\n",
    "    col(\"Total de medallas\").desc()\n",
    "    )\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones escalares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ejempo realizado para obtener las medallas ganadas por un pais se migará para poder visualizar como sería integrar SQL a un proceso de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----+\n",
      "|medalla|  equipo|sigla|\n",
      "+-------+--------+-----+\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "| Silver|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "| Bronze|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "| Silver|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "| Silver|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "| Silver|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "+-------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultadoDF\\\n",
    "    .filter(\n",
    "        resultadoDF.medalla != \"NA\"\n",
    "    )\\\n",
    "    .join(\n",
    "        deportistaOlimpicoDF,\n",
    "        deportistaOlimpicoDF.deportista_id == resultadoDF.deportista_id,\n",
    "        \"left\"\n",
    "    )\\\n",
    "    .join(\n",
    "        paisesDF,\n",
    "        paisesDF.id == deportistaOlimpicoDF.equipo_id, \n",
    "        \"left\"\n",
    "    )\\\n",
    "    .select(\n",
    "        \"medalla\",\n",
    "        \"equipo\",\n",
    "        \"sigla\"\n",
    "    )\\\n",
    "    .sort(\n",
    "        col(\"sigla\").desc()\n",
    "    )\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El uso de DF como SQL, se usa registrando un DF como tabla temportal.\n",
    "\n",
    "En el caso de realizar la conexión a una base de datos, este paso puede llegar a ser omitido. Ya que spark estará configurado para poder hacer las conexiones implicitamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadoDF.registerTempTable(\"resultado\")\n",
    "deportistaOlimpicoDF.registerTempTable(\"deportista\")\n",
    "paisesDF.registerTempTable(\"paises\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El alias asignado, será la forma en la cual sqlContext conocerá el DF internamente, ahora podemos hacer operaciones de forma tradicional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+-----------+---------+\n",
      "|deportista_id|              nombre|edadAlJugar|equipo_id|\n",
      "+-------------+--------------------+-----------+---------+\n",
      "|            1|           A Dijiang|         24|      199|\n",
      "|            2|            A Lamusi|         23|      199|\n",
      "|            3| Gunnar Nielsen Aaby|         24|      273|\n",
      "|            4|Edgar Lindenau Aabye|         34|      278|\n",
      "|            5|Christine Jacoba ...|         21|      705|\n",
      "+-------------+--------------------+-----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"SELECT * FROM deportista\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 217:>                                                        (0 + 1) / 2]\r",
      "\r",
      "[Stage 217:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----+\n",
      "|medalla|              equipo|sigla|\n",
      "+-------+--------------------+-----+\n",
      "|   Gold|            Zimbabwe|  ZIM|\n",
      "| Silver|            Zimbabwe|  ZIM|\n",
      "| Bronze|            Zimbabwe|  ZIM|\n",
      "| Silver|              Zambia|  ZAM|\n",
      "|   Gold|          Yugoslavia|  YUG|\n",
      "| Bronze|          Yugoslavia|  YUG|\n",
      "| Silver|          Yugoslavia|  YUG|\n",
      "| Bronze|West Indies Feder...|  WIF|\n",
      "| Silver|             Vietnam|  VIE|\n",
      "|   Gold|             Vietnam|  VIE|\n",
      "|   Gold|           Venezuela|  VEN|\n",
      "| Bronze|           Venezuela|  VEN|\n",
      "| Silver|           Venezuela|  VEN|\n",
      "| Silver|          Uzbekistan|  UZB|\n",
      "|   Gold|          Uzbekistan|  UZB|\n",
      "| Bronze|          Uzbekistan|  UZB|\n",
      "| Bronze|     United States-1|  USA|\n",
      "|   Gold|       United States|  USA|\n",
      "|   Gold|Seawanhaka Boat C...|  USA|\n",
      "|   Gold|New York Athletic...|  USA|\n",
      "+-------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\n",
    "                \"\"\"\n",
    "                SELECT DISTINCT medalla, equipo, sigla FROM resultado r\n",
    "                JOIN deportista d\n",
    "                ON r.deportista_id = d.deportista_id\n",
    "                JOIN paises p\n",
    "                ON p.id = d.equipo_id\n",
    "                WHERE medalla <> \"NA\"\n",
    "                ORDER BY sigla DESC\n",
    "                \"\"\"\n",
    "            )\\\n",
    "            .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.storagelevel import StorageLevel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La persistencia de datos no ocurre por defecto en un DF o RDD de Spark, por lo cual debemos de indicar con el método 'cache', por otro lado, para poder verificar si esta almacenado o no, con el método 'is_cached' verificamos su estatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medallistaXAnio.is_cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[554] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medallistaXAnio.rdd.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder verificar el tipo de almacenamiento asignado, debemos de conocer el valor de códigos que nos regresa getStorageLevel\n",
    "\n",
    "Para esto, podemos verificar en la documentación de spark:\n",
    "https://spark.apache.org/docs/2.4.6/api/python/_modules/pyspark/storagelevel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(False, True, False, False, 1)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medallistaXAnio.rdd.getStorageLevel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder cambiar el tipo de persistencia debemos de primero retirarla y posterior a eso asignarle la que deseamos.\n",
    "\n",
    "Con el método persist, asignaremos la persistencia que nosotros deseamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[554] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medallistaXAnio.rdd.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[554] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medallistaXAnio.rdd.persist(StorageLevel.MEMORY_AND_DISK_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(True, True, False, False, 2)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medallistaXAnio.rdd.getStorageLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(True, True, False, False, 2)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medallistaXAnio.rdd.getStorageLevel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, podemos crear nuestros propios esquemas de persistencia según las reglas y restricciones de negocio que tengamos en el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def __init__(self, useDisk, useMemory, useOffHeap, deserialized, replication=1):\n",
    "StorageLevel.MEMORY_AND_DISK_3 = StorageLevel(True,True,False,False,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[554] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medallistaXAnio.rdd.unpersist()\n",
    "medallistaXAnio.rdd.persist(StorageLevel.MEMORY_AND_DISK_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e55666fbbf217aa3df372b978577f47b6009e2f78e2ec76a584f49cd54a1e62c"
  },
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
