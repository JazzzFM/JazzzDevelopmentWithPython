{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mdurango/Proyect/Mlops-platzi/.venv/lib/python3.9/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/Users/mdurango/Proyect/Mlops-platzi/.venv/lib/python3.9/site-packages/pydantic/_internal/_config.py:318: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import xgboost\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import Lasso, LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora lo que vamos a hacer es ir a la UI y simulemos que algún cientifico de datos o miembro del equipo decide registrar ciertos podemos en \"staging\", y más adelante nosotros como ingenieros de ML tomamos la decisión de cual modelo registrar para producción bajo las métricas de performance obtenidas y las pruebas. Es muy importante, hacer las pruebas de validación antes de considerar un modelo en producción. Entre ellas se encuentran:\n",
    "\n",
    "#### 1. Pruebas de Funcionalidad:\n",
    "\n",
    "* Funcionalidad del Modelo: Asegurarse de que el modelo funcione correctamente en el entorno de producción con los datos reales (Se puede simular con cierta parte de la data o toda idealmente).\n",
    "* Integración del Modelo: Verificar que el modelo integrado en la infraestructura de producción responda y se comunique adecuadamente con otros componentes del sistema (partes del Pipeline).\n",
    "\n",
    "####  2. Pruebas de Rendimiento:\n",
    "* Rendimiento del Modelo: Evaluar el rendimiento del modelo en términos de velocidad de inferencia, uso de recursos (CPU, memoria), y latencia para garantizar que cumple con los requisitos de producción. (El tiempo es un factor muy importante en la generación de soluciones de negocio)\n",
    "* Escala y Carga: Probar el modelo bajo cargas esperadas para asegurar que el sistema es escalable y puede manejar la demanda prevista. (Orar para que el Kernel no muera con la carga, de lo contrario mirar formas de optimizar el código, hacer carga de datos por chuncks, paralelizar procesos, etc)\n",
    "\n",
    "#### 3. Pruebas de Robustez:\n",
    "* Robustez de estrés: Evaluar el comportamiento del modelo en condiciones adversas, como datos de entrada no esperados, valores faltantes, valores atípicos, etc. (Esto es muy importante, ya que en la vida real los datos no son perfectos, y es muy probable que el modelo se caiga si no se tiene en cuenta este factor por lo que generar pruebas unitarias para este tipo de casos es muy importante). \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions from mlflow artifacts\n",
    "\n",
    "Predict on Pandas DataFrame: Para ello debemos tener la misma representación de datos que hemos usado para entrenar el modelo, es decir, las mismas columnas y el mismo orden. Por lo que vamos a usar un par de funciones que hemos venido implementando. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(filename):\n",
    "    \"\"\" \n",
    "    This function loads a pickle file from the data_processed folder\n",
    "    and returns the data\n",
    "    Args:\n",
    "        filename (str): name of the file to load\n",
    "    Returns:\n",
    "        data (pd.DataFrame): data loaded from the pickle file\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(\"data\", \"data_processed\", f\"{filename}.pkl\")\n",
    "    with open(filepath, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_pickle(\"train\")\n",
    "X_test, y_test = load_pickle(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13269,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13269, 13692)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train.toarray().shape[0] == y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Establecer la URI de tracking\n",
    "mlflow.set_tracking_uri('sqlite:///mlflow.db')\n",
    "\n",
    "# Ahora puedes cargar tu modelo\n",
    "#logged_model = './mlruns/1/e1aedba8c8ea485c91f81b8b124c269f/artifacts/models/LogisticRegression'\n",
    "logged_model = \"logged_model = 'runs:/5f13a7a3b4804585afed5d5a10a82f7b/models/LogisticRegression'\"\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: models/LogisticRegression\n",
       "  flavor: mlflow.sklearn\n",
       "  run_id: e1aedba8c8ea485c91f81b8b124c269f"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get info from the loaded model\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = mlflow.sklearn.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2', '2', '2', ..., '2', '2', '2'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model registry and state transitions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://pbs.twimg.com/media/EoOBoWyWEAAA8In.jpg\" width=\"400\" style=\"display: block; margin: auto;\">\n",
    "</p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tener en cuenta el tiempo de ejecución\n",
    "\n",
    "* Métricas obtenidas\n",
    "\n",
    "* Size del tamaño \n",
    "\n",
    "* Las pruebas que anteriormente mencionamos. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///backend.db\")\n",
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs()\n",
    "# Extrae los IDs únicos de los experimentos\n",
    "experiment_ids = runs['experiment_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_experiment(\"regression_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = client.search_runs(experiment_ids=[\"1\"])\n",
    "for run in runs:\n",
    "    print(run.info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs= client.search_runs(\n",
    "    experiment_ids='1',\n",
    "    filter_string=\"\", #se puede usar un tag en especial o algún parámetro de interés ej: 'tags.model = \"lasso_regression\" '\n",
    "    run_view_type=mlflow.entities.ViewType.ACTIVE_ONLY,\n",
    "    max_results=5,\n",
    "    order_by=[\"metrics.rmse_valid ASC\"]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    print(f\"run id: {run.info.run_id}, rmse_valid: {run.data.metrics['rmse_valid']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promote a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"a90d6cc190014a21ba5a0dc4de13f94e\"\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "mlflow.register_model(model_uri, \"regressor_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"regressor_model\"\n",
    "latest_versions = client.get_latest_versions(name=model_name)\n",
    "for version in latest_versions:\n",
    "    print(f\" version: {version.version} , actual stage: {version._current_stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=2,\n",
    "    stage=\"Staging\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=1,\n",
    "    stage=\"Production\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando vayas a cambiar el staging de un modelo a otro estado, podemos también añadir descripciones: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.update_model_version(\n",
    "    name=model_name, \n",
    "    version=2,\n",
    "    description=f\"The model version {2} was transitioned to Production on {datetime.today().date()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test.get_label())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.get_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.get_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing a register model: \n",
    "\n",
    "De esta forma se deben hacer las pruebas con el pipeline de producción para asegurar que el modelo se comporta como se espera, además de validar la infraestructura y las pruebas que recién habíamos mencionado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OJO: Es importante que recuerdes los formatos permitidos por mlflow load_model, como dataframes, numpy arrays, etc.\n",
    "def testint_model_from_mlflow(model_name: str, stage:str, X_test: xgboost.core.DMatrix, Y_test: np.ndarray):\n",
    "    \"\"\"this function tests a model from mlflow\n",
    "    Args:\n",
    "        model_name (str): name of the model\n",
    "        stage (str): stage of the model\n",
    "        X_test (scipy.sparse._csr.csr_matrix): test data\n",
    "        Y_test (scipy.sparse._csr.csr_matrix): test target\n",
    "    Returns:\n",
    "        float: rmse of the model\n",
    "    \n",
    "    \"\"\"\n",
    "    model_uri = f\"models:/{model_name}/{stage}\"\n",
    "    model = mlflow.pyfunc.load_model(model_uri)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(Y_test, y_pred, squared=False)\n",
    "    return {\"rmse\": rmse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "testint_model_from_mlflow(model_name= \"regressor_model\", stage=\"Production\", X_test=test, Y_test=test.get_label())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ventajas de MLflow:\n",
    "\n",
    "* Gestión de Ciclo de Vida: Facilita el seguimiento de experimentos, versionado de modelos y reproducción de resultados.\n",
    "* Interoperabilidad: Es compatible con múltiples frameworks de aprendizaje automático y se integra fácilmente en flujos de trabajo existentes.\n",
    "* Abierto y Modular: Ofrece una arquitectura modular que permite la flexibilidad y personalización.\n",
    "* Trazabilidad y Reproducibilidad: Registra métricas, parámetros y artefactos para reproducir modelos y resultados.\n",
    "* Comunidad Activa: Amplia comunidad de usuarios y contribuciones continuas.\n",
    "\n",
    "\n",
    "#### Desventajas de MLflow:\n",
    "* Complejidad para Grandes Volúmenes de Datos: Puede enfrentar dificultades al manejar grandes volúmenes de datos o flujos de trabajo muy complejos.\n",
    "* Curva de Aprendizaje: Requiere tiempo para familiarizarse con todas sus funcionalidades y componentes.\n",
    "Limitaciones en Algunas Funcionalidades: Algunas funcionalidades pueden no ser tan avanzadas o flexibles como en otras herramientas especializadas.\n",
    "\n",
    "\n",
    "### Alternativas a MLflow:\n",
    "* TensorBoard: Enfoque específico para TensorFlow, útil para visualizar gráficamente métricas, grafos de modelos y más.\n",
    "* DVC (Data Version Control): Se enfoca en versionado de datos y modelos, y gestión de experimentos.\n",
    "* Comet.ml: Ofrece seguimiento de experimentos, colaboración y visualización de manera similar a MLflow.\n",
    "* Weights & Biases: Ofrece seguimiento de experimentos, colaboración y visualización de manera similar a MLflow.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones\n",
    "\n",
    "* Podemos trackear metadata\n",
    "\n",
    "* Registrar modelos\n",
    "\n",
    "* Obtener los requirimientos del ambiente de desarrollo donde fue entrenado los modelos\n",
    "\n",
    "* Podemos hacer un seguimiento de los modelos y compararlos de forma fácil y amigable con la interfaz de MLflow y en código\n",
    "\n",
    "* Hacer transiciones de estados de los modelos\n",
    "\n",
    "* Añadir anotaciones o descripciones \n",
    "\n",
    "So, ya sabes incluír el registro de modelos en nuestro pipeline de ML, ahora vamos a aprender de workflows y tasks. ¡Te espero en la próxima clase! :) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-curso-py3.9",
   "language": "python",
   "name": "mlops-curso-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
